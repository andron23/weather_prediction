{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Weather forecast.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AArRZFKopHXa"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6XTfcYUpcfW",
        "outputId": "a250f7bc-28f8-47cb-c094-fb382e59e89a"
      },
      "source": [
        "cd weather/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/weather\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWbUM3CupTmf"
      },
      "source": [
        "dataset = pd.read_csv('training.csv', sep = '\\t')"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tPRbaHtypocS",
        "outputId": "039c4a3e-8d38-4a30-d383-b4e360a244db"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date time</th>\n",
              "      <th>Temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01/01/2011</td>\n",
              "      <td>68.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01/02/2011</td>\n",
              "      <td>66.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01/03/2011</td>\n",
              "      <td>68.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01/04/2011</td>\n",
              "      <td>71.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01/05/2011</td>\n",
              "      <td>69.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3098</th>\n",
              "      <td>06/26/2019</td>\n",
              "      <td>75.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3099</th>\n",
              "      <td>06/27/2019</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3100</th>\n",
              "      <td>06/28/2019</td>\n",
              "      <td>72.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3101</th>\n",
              "      <td>06/29/2019</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3102</th>\n",
              "      <td>06/30/2019</td>\n",
              "      <td>70.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3071 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date time  Temperature\n",
              "0     01/01/2011         68.9\n",
              "1     01/02/2011         66.4\n",
              "2     01/03/2011         68.7\n",
              "3     01/04/2011         71.4\n",
              "4     01/05/2011         69.3\n",
              "...          ...          ...\n",
              "3098  06/26/2019         75.7\n",
              "3099  06/27/2019         75.0\n",
              "3100  06/28/2019         72.7\n",
              "3101  06/29/2019         71.0\n",
              "3102  06/30/2019         70.8\n",
              "\n",
              "[3071 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcSFZGYZppo4"
      },
      "source": [
        "dataset = dataset.dropna(subset=[\"Temperature\"])"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzzxtHm0qiT6"
      },
      "source": [
        "dataset=dataset.reset_index(drop=True)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDTxAVXBqnYG"
      },
      "source": [
        "training_set = dataset.iloc[:,1:2]"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZLNAe8JrRMr",
        "outputId": "3280d578-ea07-4536-da1a-5d0b21275fca"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3071, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5A1F3cesq6s"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF7e2fJmsrrL"
      },
      "source": [
        "sc = MinMaxScaler(feature_range=(0,1))"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcLmic73suTD"
      },
      "source": [
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw1joDSctAWD",
        "outputId": "118a5a7a-948a-4406-e814-1c0d4dba0897"
      },
      "source": [
        "training_set_scaled"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19927536],\n",
              "       [0.10869565],\n",
              "       [0.19202899],\n",
              "       ...,\n",
              "       [0.33695652],\n",
              "       [0.27536232],\n",
              "       [0.26811594]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozd5MDRdtBVG"
      },
      "source": [
        "x_train = []\r\n",
        "y_train = []\r\n",
        "n_future = 3 # next 4 days temperature forecast\r\n",
        "n_past = 3 # Past 30 days "
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kse3k2WtF0j"
      },
      "source": [
        "for i in range(0,len(training_set_scaled)-n_past-n_future+1):\r\n",
        "    x_train.append(training_set_scaled[i : i + n_past , 0])     \r\n",
        "    y_train.append(training_set_scaled[i + n_past : i + n_past + n_future , 0 ])"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkGZqYiktOwK"
      },
      "source": [
        "x_train , y_train = np.array(x_train), np.array(y_train)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5YAnUJXUuHL",
        "outputId": "b342a7b4-2e77-4d92-8ba1-54f001dfa5c5"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3066, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnYoQb-StZEq"
      },
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0] , x_train.shape[1], 1))"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pieNd7rVYdI",
        "outputId": "848acbb3-5d92-4fee-8a41-311ca5d29b5f"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3066, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVnrV9tjVZms",
        "outputId": "88e12e04-f81a-4ce1-bf91-7f74d10863ea"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3066, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZMXDZbntiAD"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import LSTM,Dense ,Dropout, Bidirectional"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rfCdv6tudhw",
        "outputId": "b3adf68e-b4ec-4372-cf90-b04b992997a5"
      },
      "source": [
        "import tensorflow as tf \r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue0AbYaqtk3W",
        "outputId": "7c0ea28c-40a8-4ef6-a5bc-7703200b2707"
      },
      "source": [
        "regressor = Sequential()\r\n",
        "regressor.add(Bidirectional(LSTM(units=30, return_sequences=True, input_shape = (x_train.shape[1],1) ) ))\r\n",
        "regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 30 , return_sequences=True))\r\n",
        "regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 30 , return_sequences=True))\r\n",
        "regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 30))\r\n",
        "regressor.add(Dropout(0.2))\r\n",
        "regressor.add(Dense(units = n_future,activation='linear'))\r\n",
        "regressor.compile(optimizer='adam', loss='mean_squared_error',metrics=['acc'])\r\n",
        "regressor.fit(x_train, y_train, epochs=500,batch_size=32 )"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "96/96 [==============================] - 7s 9ms/step - loss: 0.1148 - acc: 0.3198\n",
            "Epoch 2/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0133 - acc: 0.3500\n",
            "Epoch 3/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0118 - acc: 0.3273\n",
            "Epoch 4/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0104 - acc: 0.3517\n",
            "Epoch 5/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0099 - acc: 0.3430\n",
            "Epoch 6/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0090 - acc: 0.3419\n",
            "Epoch 7/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0094 - acc: 0.3339\n",
            "Epoch 8/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0087 - acc: 0.3358\n",
            "Epoch 9/500\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.0086 - acc: 0.3601\n",
            "Epoch 10/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0082 - acc: 0.3378\n",
            "Epoch 11/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0083 - acc: 0.3299\n",
            "Epoch 12/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0077 - acc: 0.3325\n",
            "Epoch 13/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0080 - acc: 0.3416\n",
            "Epoch 14/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0074 - acc: 0.3302\n",
            "Epoch 15/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0070 - acc: 0.3490\n",
            "Epoch 16/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0071 - acc: 0.3216\n",
            "Epoch 17/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0076 - acc: 0.3405\n",
            "Epoch 18/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0069 - acc: 0.3323\n",
            "Epoch 19/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0071 - acc: 0.3510\n",
            "Epoch 20/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0068 - acc: 0.3388\n",
            "Epoch 21/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0068 - acc: 0.3435\n",
            "Epoch 22/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0067 - acc: 0.3465\n",
            "Epoch 23/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0066 - acc: 0.3341\n",
            "Epoch 24/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - acc: 0.3594\n",
            "Epoch 25/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0067 - acc: 0.3567\n",
            "Epoch 26/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0065 - acc: 0.3616\n",
            "Epoch 27/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0065 - acc: 0.3766\n",
            "Epoch 28/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0070 - acc: 0.3522\n",
            "Epoch 29/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0067 - acc: 0.3724\n",
            "Epoch 30/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - acc: 0.3385\n",
            "Epoch 31/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3728\n",
            "Epoch 32/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3659\n",
            "Epoch 33/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - acc: 0.3666\n",
            "Epoch 34/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0065 - acc: 0.3693\n",
            "Epoch 35/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3876\n",
            "Epoch 36/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0068 - acc: 0.3580\n",
            "Epoch 37/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - acc: 0.3541\n",
            "Epoch 38/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - acc: 0.3698\n",
            "Epoch 39/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3632\n",
            "Epoch 40/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3777\n",
            "Epoch 41/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3895\n",
            "Epoch 42/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3740\n",
            "Epoch 43/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3885\n",
            "Epoch 44/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3754\n",
            "Epoch 45/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3726\n",
            "Epoch 46/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - acc: 0.3691\n",
            "Epoch 47/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3551\n",
            "Epoch 48/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3853\n",
            "Epoch 49/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3729\n",
            "Epoch 50/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3717\n",
            "Epoch 51/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3581\n",
            "Epoch 52/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3835\n",
            "Epoch 53/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3741\n",
            "Epoch 54/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3556\n",
            "Epoch 55/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3872\n",
            "Epoch 56/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4039\n",
            "Epoch 57/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3838\n",
            "Epoch 58/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3831\n",
            "Epoch 59/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3975\n",
            "Epoch 60/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3887\n",
            "Epoch 61/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3776\n",
            "Epoch 62/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3797\n",
            "Epoch 63/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4045\n",
            "Epoch 64/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3836\n",
            "Epoch 65/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3565\n",
            "Epoch 66/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3890\n",
            "Epoch 67/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4014\n",
            "Epoch 68/500\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0061 - acc: 0.3552\n",
            "Epoch 69/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3934\n",
            "Epoch 70/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4144\n",
            "Epoch 71/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3421\n",
            "Epoch 72/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3800\n",
            "Epoch 73/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3853\n",
            "Epoch 74/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3881\n",
            "Epoch 75/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3995\n",
            "Epoch 76/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3892\n",
            "Epoch 77/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3898\n",
            "Epoch 78/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3878\n",
            "Epoch 79/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3841\n",
            "Epoch 80/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4111\n",
            "Epoch 81/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3793\n",
            "Epoch 82/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3977\n",
            "Epoch 83/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4036\n",
            "Epoch 84/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3838\n",
            "Epoch 85/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4018\n",
            "Epoch 86/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3710\n",
            "Epoch 87/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4149\n",
            "Epoch 88/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3860\n",
            "Epoch 89/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3664\n",
            "Epoch 90/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3703\n",
            "Epoch 91/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3983\n",
            "Epoch 92/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3781\n",
            "Epoch 93/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3923\n",
            "Epoch 94/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3990\n",
            "Epoch 95/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4008\n",
            "Epoch 96/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4062\n",
            "Epoch 97/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3884\n",
            "Epoch 98/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4070\n",
            "Epoch 99/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3584\n",
            "Epoch 100/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3782\n",
            "Epoch 101/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3839\n",
            "Epoch 102/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4160\n",
            "Epoch 103/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3663\n",
            "Epoch 104/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4083\n",
            "Epoch 105/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4000\n",
            "Epoch 106/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4016\n",
            "Epoch 107/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3970\n",
            "Epoch 108/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4114\n",
            "Epoch 109/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3624\n",
            "Epoch 110/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4091\n",
            "Epoch 111/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3763\n",
            "Epoch 112/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4048\n",
            "Epoch 113/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4110\n",
            "Epoch 114/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4093\n",
            "Epoch 115/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3973\n",
            "Epoch 116/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3819\n",
            "Epoch 117/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3776\n",
            "Epoch 118/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4203\n",
            "Epoch 119/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3609\n",
            "Epoch 120/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3795\n",
            "Epoch 121/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3869\n",
            "Epoch 122/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4098\n",
            "Epoch 123/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4007\n",
            "Epoch 124/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4020\n",
            "Epoch 125/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4125\n",
            "Epoch 126/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4066\n",
            "Epoch 127/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4061\n",
            "Epoch 128/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3950\n",
            "Epoch 129/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3914\n",
            "Epoch 130/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3905\n",
            "Epoch 131/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3903\n",
            "Epoch 132/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3972\n",
            "Epoch 133/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4003\n",
            "Epoch 134/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4042\n",
            "Epoch 135/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3842\n",
            "Epoch 136/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3844\n",
            "Epoch 137/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4043\n",
            "Epoch 138/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4075\n",
            "Epoch 139/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3860\n",
            "Epoch 140/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4049\n",
            "Epoch 141/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3871\n",
            "Epoch 142/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3954\n",
            "Epoch 143/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4200\n",
            "Epoch 144/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4091\n",
            "Epoch 145/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3889\n",
            "Epoch 146/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4095\n",
            "Epoch 147/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0063 - acc: 0.3962\n",
            "Epoch 148/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3984\n",
            "Epoch 149/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3887\n",
            "Epoch 150/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3853\n",
            "Epoch 151/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4051\n",
            "Epoch 152/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3975\n",
            "Epoch 153/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4112\n",
            "Epoch 154/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3943\n",
            "Epoch 155/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3999\n",
            "Epoch 156/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3993\n",
            "Epoch 157/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4048\n",
            "Epoch 158/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.3822\n",
            "Epoch 159/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4077\n",
            "Epoch 160/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4233\n",
            "Epoch 161/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4086\n",
            "Epoch 162/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4160\n",
            "Epoch 163/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4117\n",
            "Epoch 164/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3941\n",
            "Epoch 165/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3782\n",
            "Epoch 166/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4080\n",
            "Epoch 167/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4055\n",
            "Epoch 168/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3787\n",
            "Epoch 169/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3970\n",
            "Epoch 170/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4201\n",
            "Epoch 171/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4078\n",
            "Epoch 172/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4091\n",
            "Epoch 173/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4134\n",
            "Epoch 174/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4092\n",
            "Epoch 175/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4008\n",
            "Epoch 176/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3992\n",
            "Epoch 177/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3856\n",
            "Epoch 178/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4106\n",
            "Epoch 179/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3903\n",
            "Epoch 180/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4062\n",
            "Epoch 181/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4093\n",
            "Epoch 182/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4016\n",
            "Epoch 183/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4141\n",
            "Epoch 184/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4071\n",
            "Epoch 185/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3976\n",
            "Epoch 186/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4033\n",
            "Epoch 187/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3911\n",
            "Epoch 188/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4238\n",
            "Epoch 189/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3928\n",
            "Epoch 190/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3964\n",
            "Epoch 191/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4137\n",
            "Epoch 192/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4038\n",
            "Epoch 193/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4052\n",
            "Epoch 194/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4052\n",
            "Epoch 195/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4188\n",
            "Epoch 196/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3804\n",
            "Epoch 197/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3997\n",
            "Epoch 198/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4051\n",
            "Epoch 199/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4166\n",
            "Epoch 200/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - acc: 0.3846\n",
            "Epoch 201/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4146\n",
            "Epoch 202/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4212\n",
            "Epoch 203/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3931\n",
            "Epoch 204/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3921\n",
            "Epoch 205/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.3899\n",
            "Epoch 206/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3801\n",
            "Epoch 207/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0053 - acc: 0.4061\n",
            "Epoch 208/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4123\n",
            "Epoch 209/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4014\n",
            "Epoch 210/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3957\n",
            "Epoch 211/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3942\n",
            "Epoch 212/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4118\n",
            "Epoch 213/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3997\n",
            "Epoch 214/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4302\n",
            "Epoch 215/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4090\n",
            "Epoch 216/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4254\n",
            "Epoch 217/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3949\n",
            "Epoch 218/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.3973\n",
            "Epoch 219/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3810\n",
            "Epoch 220/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4139\n",
            "Epoch 221/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4079\n",
            "Epoch 222/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4077\n",
            "Epoch 223/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4140\n",
            "Epoch 224/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4145\n",
            "Epoch 225/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4026\n",
            "Epoch 226/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4187\n",
            "Epoch 227/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3995\n",
            "Epoch 228/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3967\n",
            "Epoch 229/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4225\n",
            "Epoch 230/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4021\n",
            "Epoch 231/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3992\n",
            "Epoch 232/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4115\n",
            "Epoch 233/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3884\n",
            "Epoch 234/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4306\n",
            "Epoch 235/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4219\n",
            "Epoch 236/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4060\n",
            "Epoch 237/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4216\n",
            "Epoch 238/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4080\n",
            "Epoch 239/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4180\n",
            "Epoch 240/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4139\n",
            "Epoch 241/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3938\n",
            "Epoch 242/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3892\n",
            "Epoch 243/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3867\n",
            "Epoch 244/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3722\n",
            "Epoch 245/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4134\n",
            "Epoch 246/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3988\n",
            "Epoch 247/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4133\n",
            "Epoch 248/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4155\n",
            "Epoch 249/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4199\n",
            "Epoch 250/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4137\n",
            "Epoch 251/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4108\n",
            "Epoch 252/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3873\n",
            "Epoch 253/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4066\n",
            "Epoch 254/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4068\n",
            "Epoch 255/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - acc: 0.4231\n",
            "Epoch 256/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4179\n",
            "Epoch 257/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4173\n",
            "Epoch 258/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4076\n",
            "Epoch 259/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4030\n",
            "Epoch 260/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4111\n",
            "Epoch 261/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0064 - acc: 0.3922\n",
            "Epoch 262/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4183\n",
            "Epoch 263/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4040\n",
            "Epoch 264/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3941\n",
            "Epoch 265/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3911\n",
            "Epoch 266/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4255\n",
            "Epoch 267/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4154\n",
            "Epoch 268/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4108\n",
            "Epoch 269/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4028\n",
            "Epoch 270/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4249\n",
            "Epoch 271/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4059\n",
            "Epoch 272/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4206\n",
            "Epoch 273/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4135\n",
            "Epoch 274/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3827\n",
            "Epoch 275/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4134\n",
            "Epoch 276/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3935\n",
            "Epoch 277/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4030\n",
            "Epoch 278/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4272\n",
            "Epoch 279/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4084\n",
            "Epoch 280/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4098\n",
            "Epoch 281/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4191\n",
            "Epoch 282/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4317\n",
            "Epoch 283/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4110\n",
            "Epoch 284/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4256\n",
            "Epoch 285/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4052\n",
            "Epoch 286/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4207\n",
            "Epoch 287/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4012\n",
            "Epoch 288/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4123\n",
            "Epoch 289/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4229\n",
            "Epoch 290/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3921\n",
            "Epoch 291/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4222\n",
            "Epoch 292/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4072\n",
            "Epoch 293/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4089\n",
            "Epoch 294/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4152\n",
            "Epoch 295/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4272\n",
            "Epoch 296/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3800\n",
            "Epoch 297/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4105\n",
            "Epoch 298/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4100\n",
            "Epoch 299/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4040\n",
            "Epoch 300/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4046\n",
            "Epoch 301/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4086\n",
            "Epoch 302/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3933\n",
            "Epoch 303/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4109\n",
            "Epoch 304/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4256\n",
            "Epoch 305/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3529\n",
            "Epoch 306/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4005\n",
            "Epoch 307/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4242\n",
            "Epoch 308/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4162\n",
            "Epoch 309/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4152\n",
            "Epoch 310/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4231\n",
            "Epoch 311/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4166\n",
            "Epoch 312/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.3975\n",
            "Epoch 313/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4008\n",
            "Epoch 314/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4173\n",
            "Epoch 315/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4150\n",
            "Epoch 316/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4011\n",
            "Epoch 317/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4001\n",
            "Epoch 318/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4071\n",
            "Epoch 319/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4164\n",
            "Epoch 320/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4154\n",
            "Epoch 321/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4107\n",
            "Epoch 322/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3884\n",
            "Epoch 323/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3823\n",
            "Epoch 324/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4096\n",
            "Epoch 325/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4367\n",
            "Epoch 326/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4128\n",
            "Epoch 327/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4098\n",
            "Epoch 328/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4130\n",
            "Epoch 329/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3985\n",
            "Epoch 330/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4009\n",
            "Epoch 331/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4134\n",
            "Epoch 332/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4075\n",
            "Epoch 333/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3861\n",
            "Epoch 334/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3959\n",
            "Epoch 335/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4227\n",
            "Epoch 336/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4084\n",
            "Epoch 337/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4105\n",
            "Epoch 338/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4096\n",
            "Epoch 339/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4171\n",
            "Epoch 340/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4158\n",
            "Epoch 341/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3953\n",
            "Epoch 342/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4254\n",
            "Epoch 343/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4311\n",
            "Epoch 344/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4258\n",
            "Epoch 345/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3920\n",
            "Epoch 346/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4288\n",
            "Epoch 347/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4129\n",
            "Epoch 348/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4206\n",
            "Epoch 349/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4128\n",
            "Epoch 350/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4346\n",
            "Epoch 351/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4234\n",
            "Epoch 352/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4005\n",
            "Epoch 353/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4235\n",
            "Epoch 354/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4315\n",
            "Epoch 355/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4181\n",
            "Epoch 356/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4109\n",
            "Epoch 357/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4240\n",
            "Epoch 358/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3767\n",
            "Epoch 359/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4100\n",
            "Epoch 360/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.3848\n",
            "Epoch 361/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4211\n",
            "Epoch 362/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4171\n",
            "Epoch 363/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4211\n",
            "Epoch 364/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3990\n",
            "Epoch 365/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4132\n",
            "Epoch 366/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4121\n",
            "Epoch 367/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4316\n",
            "Epoch 368/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4057\n",
            "Epoch 369/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4076\n",
            "Epoch 370/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4119\n",
            "Epoch 371/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4144\n",
            "Epoch 372/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4262\n",
            "Epoch 373/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3860\n",
            "Epoch 374/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4170\n",
            "Epoch 375/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4135\n",
            "Epoch 376/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3785\n",
            "Epoch 377/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4158\n",
            "Epoch 378/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4092\n",
            "Epoch 379/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4139\n",
            "Epoch 380/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4116\n",
            "Epoch 381/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3974\n",
            "Epoch 382/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4256\n",
            "Epoch 383/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4140\n",
            "Epoch 384/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4127\n",
            "Epoch 385/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4245\n",
            "Epoch 386/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4099\n",
            "Epoch 387/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4268\n",
            "Epoch 388/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4352\n",
            "Epoch 389/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4012\n",
            "Epoch 390/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4124\n",
            "Epoch 391/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4121\n",
            "Epoch 392/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4156\n",
            "Epoch 393/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4152\n",
            "Epoch 394/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4152\n",
            "Epoch 395/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4019\n",
            "Epoch 396/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4106\n",
            "Epoch 397/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4273\n",
            "Epoch 398/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4329\n",
            "Epoch 399/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4296\n",
            "Epoch 400/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4381\n",
            "Epoch 401/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4295\n",
            "Epoch 402/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4159\n",
            "Epoch 403/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4114\n",
            "Epoch 404/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4232\n",
            "Epoch 405/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4144\n",
            "Epoch 406/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4181\n",
            "Epoch 407/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0061 - acc: 0.4075\n",
            "Epoch 408/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4152\n",
            "Epoch 409/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4141\n",
            "Epoch 410/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4072\n",
            "Epoch 411/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4226\n",
            "Epoch 412/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4324\n",
            "Epoch 413/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4215\n",
            "Epoch 414/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4077\n",
            "Epoch 415/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4192\n",
            "Epoch 416/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.3893\n",
            "Epoch 417/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4335\n",
            "Epoch 418/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4175\n",
            "Epoch 419/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4283\n",
            "Epoch 420/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4093\n",
            "Epoch 421/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4184\n",
            "Epoch 422/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4214\n",
            "Epoch 423/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4054\n",
            "Epoch 424/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4273\n",
            "Epoch 425/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3926\n",
            "Epoch 426/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4126\n",
            "Epoch 427/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3962\n",
            "Epoch 428/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4145\n",
            "Epoch 429/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4169\n",
            "Epoch 430/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4305\n",
            "Epoch 431/500\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0058 - acc: 0.4053\n",
            "Epoch 432/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4179\n",
            "Epoch 433/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4233\n",
            "Epoch 434/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4260\n",
            "Epoch 435/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4134\n",
            "Epoch 436/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4281\n",
            "Epoch 437/500\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0057 - acc: 0.4158\n",
            "Epoch 438/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3932\n",
            "Epoch 439/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3979\n",
            "Epoch 440/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4224\n",
            "Epoch 441/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.3861\n",
            "Epoch 442/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4224\n",
            "Epoch 443/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4215\n",
            "Epoch 444/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4115\n",
            "Epoch 445/500\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0055 - acc: 0.4088\n",
            "Epoch 446/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4068\n",
            "Epoch 447/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4040\n",
            "Epoch 448/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4411\n",
            "Epoch 449/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4070\n",
            "Epoch 450/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4067\n",
            "Epoch 451/500\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0058 - acc: 0.4199\n",
            "Epoch 452/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4259\n",
            "Epoch 453/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4097\n",
            "Epoch 454/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4237\n",
            "Epoch 455/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4031\n",
            "Epoch 456/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4040\n",
            "Epoch 457/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4084\n",
            "Epoch 458/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4002\n",
            "Epoch 459/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - acc: 0.4250\n",
            "Epoch 460/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4246\n",
            "Epoch 461/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4198\n",
            "Epoch 462/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.3875\n",
            "Epoch 463/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4142\n",
            "Epoch 464/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4097\n",
            "Epoch 465/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4205\n",
            "Epoch 466/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4273\n",
            "Epoch 467/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - acc: 0.4246\n",
            "Epoch 468/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4120\n",
            "Epoch 469/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4156\n",
            "Epoch 470/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4225\n",
            "Epoch 471/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4231\n",
            "Epoch 472/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4052\n",
            "Epoch 473/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4340\n",
            "Epoch 474/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.3915\n",
            "Epoch 475/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4208\n",
            "Epoch 476/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4196\n",
            "Epoch 477/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4229\n",
            "Epoch 478/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4178\n",
            "Epoch 479/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4067\n",
            "Epoch 480/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4138\n",
            "Epoch 481/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4265\n",
            "Epoch 482/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4251\n",
            "Epoch 483/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4300\n",
            "Epoch 484/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4129\n",
            "Epoch 485/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4268\n",
            "Epoch 486/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4083\n",
            "Epoch 487/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0054 - acc: 0.4252\n",
            "Epoch 488/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.4110\n",
            "Epoch 489/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0055 - acc: 0.3945\n",
            "Epoch 490/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3981\n",
            "Epoch 491/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4117\n",
            "Epoch 492/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.3992\n",
            "Epoch 493/500\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0055 - acc: 0.4316\n",
            "Epoch 494/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - acc: 0.4006\n",
            "Epoch 495/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4149\n",
            "Epoch 496/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0058 - acc: 0.4184\n",
            "Epoch 497/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0057 - acc: 0.4073\n",
            "Epoch 498/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4114\n",
            "Epoch 499/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0059 - acc: 0.4263\n",
            "Epoch 500/500\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0060 - acc: 0.4148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda58a9c748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1qlrOEN30v4"
      },
      "source": [
        "# read test dataset\r\n",
        "testdataset = pd.read_csv('testing.csv')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex2Xe5HG6FU-",
        "outputId": "40dd3da8-9e93-465b-864b-b3585d1bc224"
      },
      "source": [
        "#get only the temperature column\r\n",
        "testdataset.iloc[:1,1:2].values"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[73.4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU2izeJS394r"
      },
      "source": [
        "real_temperature = pd.read_csv('testing.csv')\r\n",
        "real_temperature = real_temperature.iloc[:,1:2].values\r\n",
        "testing = sc.transform(testdataset)\r\n",
        "testing = np.array(testing)\r\n",
        "testing = np.reshape(testing,(testing.shape[1],testing.shape[0],1))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nakRBtT86XdA"
      },
      "source": [
        "predicted_temperature = regressor.predict(testing)\r\n",
        "predicted_temperature = sc.inverse_transform(predicted_temperature)\r\n",
        "predicted_temperature = np.reshape(predicted_temperature,(predicted_temperature.shape[1],predicted_temperature.shape[0]))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBmUBsWw6nZz",
        "outputId": "626e982a-666b-4bcf-8a15-40fc306e9f02"
      },
      "source": [
        "len(predicted_temperature)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LERK1EA36pWj",
        "outputId": "aa4644b2-6a7a-44bc-c6be-f5903b2e13dd"
      },
      "source": [
        "real_temperature = pd.read_csv('testing.csv')\r\n",
        "real_temperature.iloc[31:34].values"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[nan, 81.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLeXWHUj8LSw"
      },
      "source": [
        "predicts = []\r\n",
        "times = []\r\n",
        "\r\n",
        "for i in range(30):\r\n",
        "  test = testdataset.iloc[:i+1,1:2].values\r\n",
        "  testing = sc.transform(test)\r\n",
        "  testing = np.array(testing)\r\n",
        "\r\n",
        "  testing = np.reshape(testing,(testing.shape[1],testing.shape[0],1))\r\n",
        "  predicted_temperature = regressor.predict(testing)\r\n",
        "  predicted_temperature = sc.inverse_transform(predicted_temperature)\r\n",
        "  predicted_temperature = np.reshape(predicted_temperature,(predicted_temperature.shape[1],predicted_temperature.shape[0]))\r\n",
        "  #time0 = 0\r\n",
        "  #for j in predicted_temperature:\r\n",
        "    #predicts.append(j[0])\r\n",
        "    #times.append(i + time0 + 1)\r\n",
        "    #time0 += 1\r\n",
        "  predicts.append(predicted_temperature[2][0])  \r\n",
        "  times.append(i+1)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYEfQs_N_kSb",
        "outputId": "5af485fb-8670-4187-b8b7-afdaecdf2c54"
      },
      "source": [
        "times"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "VFY0cAwB9emd",
        "outputId": "e2c1760e-09af-425a-b572-4a5ed128374e"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(times, predicts, 'r', range(32), real_temperature)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fda61228080>,\n",
              " <matplotlib.lines.Line2D at 0x7fda60123c18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvX-5hLg9iNa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdGId0Z6LbhJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtVug0MmLbrI"
      },
      "source": [
        "import zipfile"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcEaIyfNLdnD"
      },
      "source": [
        "with zipfile.ZipFile('fangfufu-nanning-2016-temp-pressure.zip') as file: \r\n",
        "  file.extractall('dataset/')"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69SR9Il4L5od"
      },
      "source": [
        "!rm -r dataset"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHrSTJAXMBUn",
        "outputId": "b84ae0dd-f796-4d65-8c6b-6047b29e4831"
      },
      "source": [
        "!mv -v 'weather-data' dataset"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed 'weather-data' -> 'dataset'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK9MlUWFMU99"
      },
      "source": [
        "import glob, os    \r\n",
        "df = pd.concat(map(lambda file: pd.read_csv(file, header = None), glob.glob(os.path.join('dataset/', \"2016-03-01.csv\"))))"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSVvUcUUMbCW"
      },
      "source": [
        "df = df.iloc[:,1:5]"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8rC0TgmNbqZ"
      },
      "source": [
        "df.columns = ['temperature', 'pressure', 'humidity', 'datetime']"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n-PpioSNGqK",
        "outputId": "ebcbbfc6-eb47-4322-bb54-ff7d69356365"
      },
      "source": [
        "df['datetime']"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2016-03-01 00:00:25+08:00\n",
              "1       2016-03-01 00:01:14+08:00\n",
              "2       2016-03-01 00:02:13+08:00\n",
              "3       2016-03-01 00:03:12+08:00\n",
              "4       2016-03-01 00:04:13+08:00\n",
              "                  ...            \n",
              "1435    2016-03-01 23:55:12+08:00\n",
              "1436    2016-03-01 23:56:12+08:00\n",
              "1437    2016-03-01 23:57:11+08:00\n",
              "1438    2016-03-01 23:58:11+08:00\n",
              "1439    2016-03-01 23:59:11+08:00\n",
              "Name: datetime, Length: 1440, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs4oY5OyNsLN",
        "outputId": "573e5b5d-2cf3-42c6-de6a-caa61f5d6469"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "temperature    0\n",
              "pressure       0\n",
              "humidity       0\n",
              "datetime       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0oyDGX6OUlx"
      },
      "source": [
        "training_set = df.iloc[:,0:1]"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIButFKxUerJ",
        "outputId": "6cd95fcc-fec3-454f-ee68-dc199687b098"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1440, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-K_lEhCN4xO"
      },
      "source": [
        "sc = MinMaxScaler(feature_range=(0,1))"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbZ2w25hODHe"
      },
      "source": [
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "gDzy5wJGO1VD",
        "outputId": "a017d543-5b86-49c2-9452-a13865a30f6b"
      },
      "source": [
        "training_set_scaled[:,2].mean()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-197-bf6961ffa3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_set_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmkVoV61PCvc"
      },
      "source": [
        "x_train = []\r\n",
        "y_train = []\r\n",
        "n_future = 180 # next 3 days temperature forecast\r\n",
        "n_past =  720 # Past 30 days "
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S9yuWT-Q9iU"
      },
      "source": [
        "for i in range(0,len(training_set_scaled)-n_past-n_future+1):\r\n",
        "    x_train.append(training_set_scaled[i : i + n_past])     \r\n",
        "    y_train.append(training_set_scaled[i + n_past : i + n_past + n_future])"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tQUc2jARGju",
        "outputId": "7458938b-9597-4f28-f680-3e6310e0b181"
      },
      "source": [
        "len(x_train[1])"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tfl13tKRdp9"
      },
      "source": [
        "x_train , y_train = np.array(x_train), np.array(y_train)"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H22Pc8IGRtVh",
        "outputId": "329bfeeb-a5af-45be-8a5a-2b1f03dc9795"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(541, 720, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp-uk54qRk2u"
      },
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0] , x_train.shape[1], x_train.shape[2]))"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXIRJD7DVpvo"
      },
      "source": [
        "y_train = np.reshape(y_train, (y_train.shape[0] , y_train.shape[1]))"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pym0H_abSUEg",
        "outputId": "717aae18-096e-43ae-dc2a-1f7a1606ec82"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(541, 180)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "zXhURA7SRyWT",
        "outputId": "477f82bb-cb70-4464-c635-8a059a196107"
      },
      "source": [
        "regressor = Sequential()\r\n",
        "regressor.add(Bidirectional(LSTM(units=30, return_sequences=True, input_shape = (x_train.shape[1],x_train.shape[2]) ) ))\r\n",
        "regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 30 , return_sequences=True))\r\n",
        "regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 30 , return_sequences=True))\r\n",
        "regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 30))\r\n",
        "regressor.add(Dropout(0.2))\r\n",
        "regressor.add(Dense(units = n_future,activation='linear'))\r\n",
        "regressor.compile(optimizer='adam', loss='mean_squared_error',metrics=['acc'])\r\n",
        "regressor.fit(x_train, y_train, epochs=500,batch_size=32 )"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "17/17 [==============================] - 8s 101ms/step - loss: 0.5586 - acc: 0.0000e+00\n",
            "Epoch 2/500\n",
            "17/17 [==============================] - 2s 97ms/step - loss: 0.2607 - acc: 0.0034\n",
            "Epoch 3/500\n",
            "17/17 [==============================] - 2s 97ms/step - loss: 0.0970 - acc: 0.0035\n",
            "Epoch 4/500\n",
            "17/17 [==============================] - 2s 96ms/step - loss: 0.0655 - acc: 0.0073\n",
            "Epoch 5/500\n",
            "17/17 [==============================] - 2s 97ms/step - loss: 0.0586 - acc: 0.0072\n",
            "Epoch 6/500\n",
            "17/17 [==============================] - 2s 98ms/step - loss: 0.0525 - acc: 0.0142\n",
            "Epoch 7/500\n",
            " 3/17 [====>.........................] - ETA: 1s - loss: 0.0499 - acc: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-233-b86c3d084d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_future\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O9BobnBCR4Q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATJE5JYREbGS",
        "outputId": "4d709176-df6c-4edb-b35d-b833383d39c5"
      },
      "source": [
        "dataset = pd.read_csv('city_temperature.csv')"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpG4WFP-Eeqp"
      },
      "source": [
        "dataset = dataset.loc[(dataset.City == 'Moscow') & (dataset.Year != 2020)]"
      ],
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt0E85WUFqSD"
      },
      "source": [
        "training_set = dataset.iloc[:,7:8]"
      ],
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "_o0wODzhHzpl",
        "outputId": "fc5a42c5-d76b-4a99-e5db-9b3a3180ae25"
      },
      "source": [
        "training_set"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AvgTemperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>878256</th>\n",
              "      <td>32.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878257</th>\n",
              "      <td>31.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878258</th>\n",
              "      <td>26.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878259</th>\n",
              "      <td>15.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878260</th>\n",
              "      <td>23.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887383</th>\n",
              "      <td>30.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887384</th>\n",
              "      <td>29.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887385</th>\n",
              "      <td>25.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887386</th>\n",
              "      <td>26.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887387</th>\n",
              "      <td>33.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9132 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        AvgTemperature\n",
              "878256            32.3\n",
              "878257            31.7\n",
              "878258            26.8\n",
              "878259            15.9\n",
              "878260            23.8\n",
              "...                ...\n",
              "887383            30.4\n",
              "887384            29.3\n",
              "887385            25.3\n",
              "887386            26.7\n",
              "887387            33.8\n",
              "\n",
              "[9132 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD64XkkyGTRp"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cEIFA9NcG_13",
        "outputId": "f1adb660-7b54-4f9e-eaa0-33742ca6aeef"
      },
      "source": [
        "dataset[dataset.Year == 2019]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Region</th>\n",
              "      <th>Country</th>\n",
              "      <th>State</th>\n",
              "      <th>City</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Year</th>\n",
              "      <th>AvgTemperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>887023</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>24.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887024</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2019</td>\n",
              "      <td>26.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887025</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2019</td>\n",
              "      <td>26.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887026</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2019</td>\n",
              "      <td>23.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887027</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2019</td>\n",
              "      <td>21.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887383</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>12</td>\n",
              "      <td>27</td>\n",
              "      <td>2019</td>\n",
              "      <td>30.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887384</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>12</td>\n",
              "      <td>28</td>\n",
              "      <td>2019</td>\n",
              "      <td>29.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887385</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>2019</td>\n",
              "      <td>25.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887386</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>2019</td>\n",
              "      <td>26.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887387</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>2019</td>\n",
              "      <td>33.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>365 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Region Country State    City  Month  Day  Year  AvgTemperature\n",
              "887023  Europe  Russia   NaN  Moscow      1    1  2019            24.3\n",
              "887024  Europe  Russia   NaN  Moscow      1    2  2019            26.6\n",
              "887025  Europe  Russia   NaN  Moscow      1    3  2019            26.4\n",
              "887026  Europe  Russia   NaN  Moscow      1    4  2019            23.1\n",
              "887027  Europe  Russia   NaN  Moscow      1    5  2019            21.3\n",
              "...        ...     ...   ...     ...    ...  ...   ...             ...\n",
              "887383  Europe  Russia   NaN  Moscow     12   27  2019            30.4\n",
              "887384  Europe  Russia   NaN  Moscow     12   28  2019            29.3\n",
              "887385  Europe  Russia   NaN  Moscow     12   29  2019            25.3\n",
              "887386  Europe  Russia   NaN  Moscow     12   30  2019            26.7\n",
              "887387  Europe  Russia   NaN  Moscow     12   31  2019            33.8\n",
              "\n",
              "[365 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-tzQAg3IG_4"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Ox274eINGO"
      },
      "source": [
        "sc = MinMaxScaler(feature_range=(0,1))"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbZKMedMIQO8"
      },
      "source": [
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2rl3QGgIdma"
      },
      "source": [
        "training_set_scaled = np.round(training_set_scaled,2)"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNu3cmnxId3X"
      },
      "source": [
        "x_train = []\r\n",
        "y_train = []\r\n",
        "n_future = 1 # next 4 days temperature forecast\r\n",
        "n_past = 3 # Past 30 days "
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoN-j_I4Io3e"
      },
      "source": [
        "for i in range(0,len(training_set_scaled)-n_past-n_future+1):\r\n",
        "    x_train.append(training_set_scaled[i : i + n_past , 0])     \r\n",
        "    y_train.append(training_set_scaled[i + n_past : i + n_past + n_future , 0 ])"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHXV1xSYIyw_"
      },
      "source": [
        "x_train , y_train = np.array(x_train), np.array(y_train)\r\n",
        "x_train = np.reshape(x_train, (x_train.shape[0] , x_train.shape[1], 1))"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jHAc_RGqPFe",
        "outputId": "816e858f-b508-44b8-c949-296f54ec9a74"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9129, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YLaPGUaagNH",
        "outputId": "2b433ef2-c2c1-4d6d-a939-1c6675a76231"
      },
      "source": [
        "training_set_scaled[0:10]"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7 ],\n",
              "       [0.7 ],\n",
              "       [0.68],\n",
              "       [0.62],\n",
              "       [0.66],\n",
              "       [0.61],\n",
              "       [0.61],\n",
              "       [0.63],\n",
              "       [0.62],\n",
              "       [0.58]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVgtF1c-I0fn",
        "outputId": "71a50ef8-c0ab-4691-af7e-96ca52f9a80b"
      },
      "source": [
        "x_train[1]"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7 ],\n",
              "       [0.68],\n",
              "       [0.62],\n",
              "       [0.66],\n",
              "       [0.61],\n",
              "       [0.61],\n",
              "       [0.63]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqs-H96gaeP4",
        "outputId": "1557a38c-d542-47fd-d3a3-9362bf7dbf87"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.63],\n",
              "       [0.62],\n",
              "       [0.58],\n",
              "       ...,\n",
              "       [0.67],\n",
              "       [0.67],\n",
              "       [0.71]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-ejl7YbI-S1",
        "outputId": "d84799ca-382b-4d6a-e1d2-a9ac523f43b3"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import LSTM,Dense ,Dropout, Bidirectional, Activation\r\n",
        "regressor = Sequential()\r\n",
        "regressor.add(Bidirectional(LSTM(units=3, return_sequences=True, input_shape = (x_train.shape[1],1) ) ))\r\n",
        "#regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 3 , return_sequences=True))\r\n",
        "#regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 3 , return_sequences=True))\r\n",
        "#regressor.add(Dropout(0.2))\r\n",
        "regressor.add(LSTM(units= 3 , return_sequences=True))\r\n",
        "#regressor.add(Dropout(0.2))\r\n",
        "\r\n",
        "\r\n",
        "regressor.add(LSTM(units= 3))\r\n",
        "regressor.add(Dense(units = n_future,activation='linear'))\r\n",
        "#regressor.add(Activation(\"relu\"))\r\n",
        "regressor.compile(optimizer='adam', loss='mean_squared_error')\r\n",
        "regressor.fit(x_train, y_train, epochs=100,batch_size=32 )"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "286/286 [==============================] - 11s 10ms/step - loss: 0.3271\n",
            "Epoch 2/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0114\n",
            "Epoch 3/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0098\n",
            "Epoch 4/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0053\n",
            "Epoch 5/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 6/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 7/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0033\n",
            "Epoch 8/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0033\n",
            "Epoch 9/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 10/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0032\n",
            "Epoch 11/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 12/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0039\n",
            "Epoch 13/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0033\n",
            "Epoch 14/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 15/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0024\n",
            "Epoch 16/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0029\n",
            "Epoch 17/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0028\n",
            "Epoch 18/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 19/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0032\n",
            "Epoch 20/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 21/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 22/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0031\n",
            "Epoch 23/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 24/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0025\n",
            "Epoch 25/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0031\n",
            "Epoch 26/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 27/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0024\n",
            "Epoch 28/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 29/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 30/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0031\n",
            "Epoch 31/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 32/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0025\n",
            "Epoch 33/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0032\n",
            "Epoch 34/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0021\n",
            "Epoch 35/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 36/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0019\n",
            "Epoch 37/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 38/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 39/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0028\n",
            "Epoch 40/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0025\n",
            "Epoch 41/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0018\n",
            "Epoch 42/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0025\n",
            "Epoch 43/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0021\n",
            "Epoch 44/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0033\n",
            "Epoch 45/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 46/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0023\n",
            "Epoch 47/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0025\n",
            "Epoch 48/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0020\n",
            "Epoch 49/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 50/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 51/100\n",
            "286/286 [==============================] - 3s 9ms/step - loss: 0.0025\n",
            "Epoch 52/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 53/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 54/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 55/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0024\n",
            "Epoch 56/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0029\n",
            "Epoch 57/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 58/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0028\n",
            "Epoch 59/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0022\n",
            "Epoch 60/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 61/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 62/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0029\n",
            "Epoch 63/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 64/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 65/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 66/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0028\n",
            "Epoch 67/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0024\n",
            "Epoch 68/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0024\n",
            "Epoch 69/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 70/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0039\n",
            "Epoch 71/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0023\n",
            "Epoch 72/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0023\n",
            "Epoch 73/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0028\n",
            "Epoch 74/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0022\n",
            "Epoch 75/100\n",
            "286/286 [==============================] - 3s 9ms/step - loss: 0.0029\n",
            "Epoch 76/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 77/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 78/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0025\n",
            "Epoch 79/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0029\n",
            "Epoch 80/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 81/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0028\n",
            "Epoch 82/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0031\n",
            "Epoch 83/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0028\n",
            "Epoch 84/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n",
            "Epoch 85/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 86/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0023\n",
            "Epoch 87/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0025\n",
            "Epoch 88/100\n",
            "286/286 [==============================] - 3s 9ms/step - loss: 0.0027\n",
            "Epoch 89/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0033\n",
            "Epoch 90/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0024\n",
            "Epoch 91/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 92/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0020\n",
            "Epoch 93/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 94/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0028\n",
            "Epoch 95/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0020\n",
            "Epoch 96/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 97/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0030\n",
            "Epoch 98/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0027\n",
            "Epoch 99/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0021\n",
            "Epoch 100/100\n",
            "286/286 [==============================] - 3s 10ms/step - loss: 0.0026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f36478226d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-l2Nd2CiMhfm",
        "outputId": "d25adcf6-c618-4b91-92c6-ac66f0aae2c7"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import LSTM,Dense ,Dropout, Bidirectional, Activation, GRU\r\n",
        "regressor = Sequential()\r\n",
        "regressor.add(GRU(units=3, return_sequences=True, input_shape = (x_train.shape[1],1)))\r\n",
        "regressor.add(Dense(units = n_future,activation='sigmoid'))\r\n",
        "regressor.compile(optimizer='adam', loss='mean_squared_error',metrics=['acc'])\r\n",
        "regressor.fit(x_train, y_train, epochs=500,batch_size=32 )"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-c56dc50a0832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1198 mean_squared_error\n        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py:10251 squared_difference\n        \"SquaredDifference\", x=x, y=y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:750 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:592 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3536 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:2016 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 7 and 3 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential_24/gru_32/transpose_1, IteratorGetNext:1)' with input shapes: [?,7,7], [?,3].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70OppSlJOwtc"
      },
      "source": [
        "lstm_layer1 = GRU(units=7, return_sequences=True, input_shape = (x_train.shape[1],1))"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9dSuBt-O1Ge"
      },
      "source": [
        "x1 = lstm_layer1(x_train)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cozla6hPBg-"
      },
      "source": [
        "lstm_layer2 = GRU(units=7, return_sequences=True, input_shape = (x_train.shape[1],7))"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrGwia0ZPFP8"
      },
      "source": [
        "x1 = lstm_layer2(x1)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQwbZzUJPNiB"
      },
      "source": [
        "layer3 = Dense(units = n_future,activation='relu')"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKmx7PAiPh13",
        "outputId": "464c8ea0-e16d-4f60-fbc7-30bc84a202b7"
      },
      "source": [
        "x1.shape"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([9123, 7, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ILrfWAOPPNJ"
      },
      "source": [
        "x1 = layer3(x1)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScdSyKdTPwgI"
      },
      "source": [
        "layer4 = Dense(units = n_future,activation='sigmoid')"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdOt5QNUPR0T"
      },
      "source": [
        "layer4(x1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujRGimdLQBYC",
        "outputId": "cff7e10d-cad6-4fd8-fb23-db0a006a748f"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9123, 7, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqsqHGHycUd8",
        "outputId": "e67223d8-17c0-4bf4-ad9e-051d4819b8f9"
      },
      "source": [
        "dataset_test = pd.read_csv('city_temperature.csv')\r\n",
        "ds = dataset_test.loc[(dataset_test.City == 'Moscow') & (dataset_test.Year == 2020)].iloc[:,7:8].round(3)\r\n",
        "training_set_scaled = sc.fit_transform(dataset_test.loc[(dataset_test.City == 'Moscow') & (dataset_test.Year == 2020)].iloc[:,7:8].round(3))[0:132]"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3zWD9SmrNce"
      },
      "source": [
        "x_test = []\r\n",
        "for i in range(0,len(training_set_scaled)-n_past-n_future+1):\r\n",
        "    x_test.append(training_set_scaled[i : i + n_past , 0])     \r\n",
        "   \r\n",
        "x_test  = np.array(x_test)\r\n",
        "x_test = np.reshape(x_test, (x_test.shape[0] , x_test.shape[1], 1))"
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vrdxui8ko8d",
        "outputId": "219812cd-7066-44cb-ed99-d0530ec0b15c"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjb7VU5urn23",
        "outputId": "3bf8e9b3-99be-4057-cfb5-5ac78e57d193"
      },
      "source": [
        "training_set_scaled.shape"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3apc-xbfaZ9"
      },
      "source": [
        "training_set_scaled = training_set_scaled.reshape(-1,3,1)"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "xsrxb3SBeVRz",
        "outputId": "9eef9079-ebea-45c6-ca74-26b66ec16f76"
      },
      "source": [
        "dataset.loc[(dataset.City == 'Moscow') & (dataset.Year == 2020)]"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Region</th>\n",
              "      <th>Country</th>\n",
              "      <th>State</th>\n",
              "      <th>City</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Year</th>\n",
              "      <th>AvgTemperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>887388</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>29.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887389</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2020</td>\n",
              "      <td>32.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887390</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2020</td>\n",
              "      <td>32.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887391</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2020</td>\n",
              "      <td>30.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887392</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2020</td>\n",
              "      <td>31.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887517</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>2020</td>\n",
              "      <td>52.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887518</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>2020</td>\n",
              "      <td>55.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887519</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>2020</td>\n",
              "      <td>59.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887520</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2020</td>\n",
              "      <td>61.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887521</th>\n",
              "      <td>Europe</td>\n",
              "      <td>Russia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Moscow</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>2020</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>134 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Region Country State    City  Month  Day  Year  AvgTemperature\n",
              "887388  Europe  Russia   NaN  Moscow      1    1  2020            29.2\n",
              "887389  Europe  Russia   NaN  Moscow      1    2  2020            32.3\n",
              "887390  Europe  Russia   NaN  Moscow      1    3  2020            32.7\n",
              "887391  Europe  Russia   NaN  Moscow      1    4  2020            30.1\n",
              "887392  Europe  Russia   NaN  Moscow      1    5  2020            31.6\n",
              "...        ...     ...   ...     ...    ...  ...   ...             ...\n",
              "887517  Europe  Russia   NaN  Moscow      5    9  2020            52.7\n",
              "887518  Europe  Russia   NaN  Moscow      5   10  2020            55.6\n",
              "887519  Europe  Russia   NaN  Moscow      5   11  2020            59.5\n",
              "887520  Europe  Russia   NaN  Moscow      5   12  2020            61.5\n",
              "887521  Europe  Russia   NaN  Moscow      5   13  2020            36.0\n",
              "\n",
              "[134 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv9m4CimcTRR"
      },
      "source": [
        "predicted_temperature = regressor.predict(x_test)\r\n",
        "predicted_temperature = sc.inverse_transform(predicted_temperature)\r\n",
        "#predicted_temperature = np.reshape(predicted_temperature,(predicted_temperature.shape[1],predicted_temperature.shape[0]))"
      ],
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOYVdL77fzZM"
      },
      "source": [
        "predicted_temperature = list(map(lambda x: x[2], predicted_temperature))"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6t0QsRhjRa_",
        "outputId": "9f731634-fb04-41d9-84f9-d6404af6d96a"
      },
      "source": [
        "predicted_temperature.shape"
      ],
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 377
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dKvULM2rxkp",
        "outputId": "ee9c69a3-d77e-441a-c374-938d99873c66"
      },
      "source": [
        "predicted_temperature"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[38.574146],\n",
              "       [37.89325 ],\n",
              "       [38.03286 ],\n",
              "       [37.931133],\n",
              "       [37.700974],\n",
              "       [38.313522],\n",
              "       [38.581017],\n",
              "       [38.271744],\n",
              "       [38.062763],\n",
              "       [37.401615],\n",
              "       [38.441223],\n",
              "       [38.71669 ],\n",
              "       [38.41022 ],\n",
              "       [39.101612],\n",
              "       [39.46768 ],\n",
              "       [38.083004],\n",
              "       [37.55575 ],\n",
              "       [38.58405 ],\n",
              "       [39.374912],\n",
              "       [38.080536],\n",
              "       [36.92093 ],\n",
              "       [37.73691 ],\n",
              "       [38.971687],\n",
              "       [38.283546],\n",
              "       [37.874252],\n",
              "       [37.332157],\n",
              "       [38.103493],\n",
              "       [38.74005 ],\n",
              "       [38.09351 ],\n",
              "       [37.861313],\n",
              "       [38.353706],\n",
              "       [38.80544 ],\n",
              "       [37.6056  ],\n",
              "       [36.953808],\n",
              "       [37.346584],\n",
              "       [37.42253 ],\n",
              "       [37.452415],\n",
              "       [38.494713],\n",
              "       [39.253284],\n",
              "       [38.64652 ],\n",
              "       [38.20551 ],\n",
              "       [37.530228],\n",
              "       [38.07408 ],\n",
              "       [38.322857],\n",
              "       [38.02985 ],\n",
              "       [39.69144 ],\n",
              "       [40.518147],\n",
              "       [39.338577],\n",
              "       [39.159172],\n",
              "       [38.779884],\n",
              "       [38.71676 ],\n",
              "       [38.341515],\n",
              "       [38.524136],\n",
              "       [37.9589  ],\n",
              "       [37.851418],\n",
              "       [38.71744 ],\n",
              "       [38.397926],\n",
              "       [37.67676 ],\n",
              "       [38.54597 ],\n",
              "       [39.526733],\n",
              "       [39.46831 ],\n",
              "       [40.1736  ],\n",
              "       [41.064117],\n",
              "       [40.995644],\n",
              "       [43.670986],\n",
              "       [42.86083 ],\n",
              "       [42.797585],\n",
              "       [42.704845],\n",
              "       [42.229313],\n",
              "       [42.201378],\n",
              "       [40.822468],\n",
              "       [37.86825 ],\n",
              "       [36.582977],\n",
              "       [37.800438],\n",
              "       [40.577526],\n",
              "       [42.404343],\n",
              "       [44.76669 ],\n",
              "       [39.642254],\n",
              "       [36.98813 ],\n",
              "       [37.210114],\n",
              "       [37.651554],\n",
              "       [38.217697],\n",
              "       [40.449417],\n",
              "       [44.96234 ],\n",
              "       [46.745926],\n",
              "       [49.975063],\n",
              "       [50.036804],\n",
              "       [37.516636],\n",
              "       [36.094807],\n",
              "       [37.776386],\n",
              "       [39.57919 ],\n",
              "       [42.852932],\n",
              "       [40.732864],\n",
              "       [37.714073],\n",
              "       [38.0508  ],\n",
              "       [40.29907 ],\n",
              "       [44.56828 ],\n",
              "       [48.16697 ],\n",
              "       [43.410896],\n",
              "       [38.15763 ],\n",
              "       [38.730476],\n",
              "       [46.62703 ],\n",
              "       [43.532497],\n",
              "       [38.431187],\n",
              "       [38.97081 ],\n",
              "       [39.240376],\n",
              "       [38.87305 ],\n",
              "       [39.323822],\n",
              "       [39.84065 ],\n",
              "       [41.703316],\n",
              "       [41.580544],\n",
              "       [41.8526  ],\n",
              "       [40.395462],\n",
              "       [40.596233],\n",
              "       [41.154217],\n",
              "       [42.304565],\n",
              "       [42.887817],\n",
              "       [47.140038],\n",
              "       [42.503796],\n",
              "       [44.540775],\n",
              "       [51.0127  ],\n",
              "       [58.666283],\n",
              "       [57.20869 ],\n",
              "       [58.797142],\n",
              "       [57.622272],\n",
              "       [55.784214],\n",
              "       [49.82036 ],\n",
              "       [51.528267],\n",
              "       [55.047787]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "JlYhdGdTf9U1",
        "outputId": "35227a3c-6f0f-43a3-87ba-54c2506db531"
      },
      "source": [
        "plt.plot(range(129), predicted_temperature, 'r', range(134), ds)"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3616b848d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f3616b849e8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 384
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvrxU9D8gBUL",
        "outputId": "0ba7dc23-0bdd-47f7-9d76-ce271302f479"
      },
      "source": [
        "!git init"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/weather/.git/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah7We-bysamK"
      },
      "source": [
        "!git add ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMqf3KrWsJSE",
        "outputId": "582e53ce-360c-47a1-a33d-02c09bffa76f"
      },
      "source": [
        "!git commit -m \"Start experiments\""
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch master\n",
            "\n",
            "Initial commit\n",
            "\n",
            "Untracked files:\n",
            "\t\u001b[31mcity_temperature.csv\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QKFJ8b2sRgs"
      },
      "source": [
        "!git config --global user.email \"andron@alexanyan.tech\""
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH4FRkp_sVT8"
      },
      "source": [
        "!git config --global user.name \"andron23\""
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i7fZhfgsXYs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}